{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline et Régression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be interested in the implementation of the perceptron algorithm (Rosenblatt, 68), Adaline (Widrow et Hoff, 60) and Logisitc Regression (Cox, 66) whose pseudo-code are the following:\n",
    "\n",
    "Perceptron:\n",
    "`Input: Train, eta, MaxEp\n",
    "init: w\n",
    "epoch = 0\n",
    "err = 1\n",
    "m = len(Train)\n",
    "while epoque <= MaxEp and err! = 0\n",
    "    err = 0\n",
    "    for i in 1: m\n",
    "        h <- w * x\n",
    "        if (y * h <= 0)\n",
    "            w <- w + eta * y * x\n",
    "            err <- err + 1\n",
    "     epoch <- epoch + 1\n",
    "output: w`\n",
    "\n",
    "Adaline:\n",
    "`input: Train, eta, MaxEp\n",
    "init : w\n",
    "epoque=0\n",
    "err=1\n",
    "m = len(Train)\n",
    "while epoque<=MaxEp and err!=0\n",
    "    err=0\n",
    "    for i in 1:m\n",
    "        h <- w*x\n",
    "        if(y*h<=0)\n",
    "           err <- err+1\n",
    "        w <- w + eta*(y-dp)*x\n",
    "     epoque <- epoque+1\n",
    "output: w`\n",
    "\n",
    "Logistic Regression:\n",
    "`input: Train, eta, MaxEp\n",
    "init : w\n",
    "epoque=0\n",
    "err=1\n",
    "m = len(Train)\n",
    "while epoque<=MaxEp and err!=0\n",
    "    err=0\n",
    "    for i in 1:m\n",
    "        choisir un exemple (x,y) de Train de façon aléatoire\n",
    "        h <- w*x\n",
    "        if(y*h<=0)\n",
    "           err <- err+1\n",
    "        w <- w + eta*y*(1-sigm(y*dp))*x\n",
    "     epoque <- epoque+1\n",
    "output: w`\n",
    "\n",
    "1. Create a list of 4 elements corresponding to the logical AND example called `Train`:\n",
    "$Train=\\{((+1,+1),+1),((-1,+1),-1),((-1,-1),-1),((+1,-1),-1)\\}$\n",
    "\n",
    "Each element of the list is a list which last characteristic is the class of the example and the first characteristics their coordinates.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=[[1,1,1], [-1,1,-1], [-1,-1,-1], [1,-1,-1]] # To be filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Code the Perceptron, Adaline and LR (Logistic regression) programs\n",
    "\n",
    "Hint: You can write a function that calculates the dot product between an example $\\mathbf{x} = (x_1, \\ldots, x_d)$ and the weight vector $\\mathbf{w} = (w_0, w_1, \\ldots, w_d)$: \n",
    "$ h(\\mathbf{x},\\mathbf{w}) = w_0 + \\ sum_ {j = 1} ^ d w_j x_j $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply the three learning models on the logical AND, and calculate the model error rate on this basis.\n",
    "\n",
    "Hint: You can write a function that takes a weight vector $\\mathbf{w}$ and an example $(\\mathbf{x},y)$ and calculates the error rate of the model with weight $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "def h_(x,w):\n",
    "    # The prediction of the model\n",
    "    Pred=w[0] + np.dot(x,w[1:])\n",
    "    return Pred\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "def Perceptron(Train,eta,MaxEp):\n",
    "    # Perceptron Algorithm \n",
    "    d=len(Train[0])-1\n",
    "    m=len(Train)\n",
    "    W=[0.0 for i in range(d+1)] \n",
    "    \n",
    "    epoque = 0\n",
    "    err = 1\n",
    "    while (epoque<=MaxEp and err !=0):\n",
    "        err=0\n",
    "        for i in range(0,m):\n",
    "            X, y = Train[i][0:d], Train[i][d]\n",
    "            h = h_(X,W)\n",
    "            X.insert(0,1)\n",
    "            if(y*h <= 0):\n",
    "                W = np.sum([W,np.dot(eta*y,X)], axis=0)\n",
    "                err = err + 1\n",
    "        epoque = epoque + 1    \n",
    "    return W\n",
    "\n",
    "\n",
    "def Adaline(Train,eta,MaxEp):\n",
    "    # Adaline Algorithm \n",
    "    d=len(Train[0])-1\n",
    "    m=len(Train)\n",
    "    W=[0.0 for i in range(d+1)]\n",
    "    \n",
    "    epoque=0\n",
    "    err=1\n",
    "    while(epoque<=MaxEp and err!=0):\n",
    "        err=0\n",
    "        for i in range(0,m):\n",
    "            X, y = Train[i][0:d], Train[i][d]\n",
    "            h = h_(X,W)\n",
    "            X.insert(0,1)\n",
    "            if(y*h<=0):\n",
    "                err = err+1\n",
    "            W = np.sum([W, np.dot(eta*(y-h),X)], axis=0)\n",
    "        epoque = epoque+1 \n",
    "    return W\n",
    "\n",
    "def LR(Train,eta,MaxEp):\n",
    "    # Logisitc Regression Algorithm \n",
    "    d=len(Train[0])-1\n",
    "    m=len(Train)\n",
    "    W=[0.0 for i in range(d+1)]\n",
    "    \n",
    "    epoque=0\n",
    "    err=1\n",
    "    while(epoque<=MaxEp and err!=0):\n",
    "        err=0\n",
    "        for i in range(0,m):\n",
    "            e = rd.randint(0,m-1) #choisir un exemple (x,y) de Train de façon aléatoire\n",
    "            X, y = Train[e][0:d], Train[e][d]\n",
    "            h = h_(X,W)\n",
    "            X.insert(0,1)\n",
    "            if(y*h<=0):\n",
    "                err = err+1\n",
    "            W = np.sum([W, np.dot(eta*y*(1-sigmoid(y*h)),X)] , axis=0)\n",
    "        epoque = epoque+1    \n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP = Perceptron(Train,1,20)\n",
    "\n",
    "# Train2 = [[1,1,1], [-1,1,1], [-1,-1,-1], [1,-1,1]] #OR\n",
    "# W2, err2 = Perceptron(Train2,1,20)\n",
    "# W2\n",
    "\n",
    "\n",
    "WA = Adaline(Train,0.01,20)\n",
    "\n",
    "# WA2, errA2 = Adaline(Train2,0.01,20)\n",
    "# WA2\n",
    "\n",
    "WL = LR(Train, 0.001, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmpiricalRisk(data,w):\n",
    "    nb_error=0\n",
    "    for i in range(len(data)):\n",
    "        X=data[i][:len(data[0])-1]\n",
    "        y=data[i][len(data[0])-1]\n",
    "        X.insert(0,1)\n",
    "        if(y*np.dot(w,X)<=0):\n",
    "            nb_error+=1\n",
    "    return nb_error/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We are now going to focus on the behavior of the three models on http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks), https://archive.ics.uci.edu/ml/datasets/spambase, https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29, https://archive.ics.uci.edu/ml/datasets/Ionosphere. These files are in the current respository with the names `sonar.txt`; `spam.txt`; `wdbc.txt` and `ionoshpere.txt`. We can use the following `ReadCollection` function in order to read the files in the form of the training set that is requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def Normalize(x):\n",
    "    norm=0.0\n",
    "    for e in x:\n",
    "        norm+=e**2\n",
    "    for i in range(len(x)):\n",
    "        x[i]/=sqrt(norm)\n",
    "    return x\n",
    "\n",
    "# Read wdbc.txt file in the Python format of request training set \n",
    "def ReadCollection(filename):\n",
    "    tag_df=pd.read_table(filename,sep=',',header=None)\n",
    "    Dic={'M': -1, 'B': +1}\n",
    "    X=[]\n",
    "    for e in range(len(tag_df)):\n",
    "        x=list(tag_df.loc[e,:])\n",
    "        x.pop(0)\n",
    "        cls=x.pop(0)\n",
    "        x=Normalize(x)\n",
    "        x.insert(len(x),Dic[cls])\n",
    "        X.append(x)\n",
    "\n",
    "    \n",
    "    random.shuffle(X)\n",
    "\n",
    "    return X\n",
    "def ReadCollection2(filename):\n",
    "    tag_df=pd.read_table(filename,sep=',',header=None)\n",
    "    if(filename == 'ionosphere.txt'): \n",
    "        Dic={'g': -1, 'b': +1}\n",
    "    elif(filename == 'sonar.txt'): \n",
    "        Dic={'M': -1, 'R': +1}\n",
    "    if(filename == 'spam.txt'): \n",
    "        Dic={0: -1, 1: +1} #1 and 0\n",
    "    X=[]\n",
    "    for e in range(len(tag_df)):\n",
    "        x=list(tag_df.loc[e,:])\n",
    "        cls=x.pop(len(x)-1)\n",
    "        x=Normalize(x)\n",
    "        x.insert(len(x),Dic[cls])\n",
    "        X.append(x)\n",
    "\n",
    "    \n",
    "    random.shuffle(X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc = ReadCollection('wdbc.txt')\n",
    "iono = ReadCollection2('ionosphere.txt')\n",
    "sonar = ReadCollection2('sonar.txt')\n",
    "spam = ReadCollection2('spam.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Run the three models on these files with $\\eta=0.01$ et $\\eta=0.1$ and `MaxEp=500`.\n",
    " \n",
    " 3. Report in the table below the average of the error rates on the test by repeating each experiment 20 times. \n",
    " \n",
    " <br>\n",
    " <br>\n",
    " \n",
    " \n",
    " <center> $\\eta=0.01$, MaxE$=500$ </center>\n",
    "    \n",
    "    \n",
    "  | Collection | Perceptron | Adaline |    RL    |\n",
    "  |------------|------------|---------|----------|\n",
    "  |   WDBC     |0.10069930  |0.077622 |0.0926573 |                 \n",
    "  | Ionosphere |0.10909090  |0.102272 |0.0738636 |\n",
    "  |   Sonar    |0.26634615  |0.244230 |0.2663461 |\n",
    "  |   Spam     |            |         |          |\n",
    " \n",
    " <br><br>\n",
    "  \n",
    "  <center> $\\eta=0.1$, MaxEp$=500$ </center>\n",
    "    \n",
    "    \n",
    "  | Collection | Perceptron | Adaline |    RL    |\n",
    "  |------------|------------|---------|----------|\n",
    "  |   WDBC     |0.12797     |0.091958 |0.086713  |                 \n",
    "  | Ionosphere |0.1261363   |0.104545 |0.0988636 |\n",
    "  |   Sonar    |0.3038461   |0.300961 |0.254807  |\n",
    "  |   Spam     |0.2076455   |0.270026 |0.1632927 |\n",
    "  \n",
    "  Hint: you can use the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errAllModelsForEachDataSet(X,eta):\n",
    "    errP=errA=errL=0.0\n",
    "    for i in range(20):\n",
    "        x_train ,x_test = train_test_split(X,test_size=0.25)\n",
    "        WLP=Perceptron(x_train,eta,500)\n",
    "        errP+=EmpiricalRisk(x_test,WLP)\n",
    "        WLA=Adaline(x_train,eta,500)\n",
    "        errA+=EmpiricalRisk(x_test,WLA)\n",
    "        WLR=LR(x_train,eta,500)\n",
    "        errL+=EmpiricalRisk(x_test,WLR)\n",
    "\n",
    "    print(\"Err perceptron=\",errP/float(20),\"Err Adaline=\",errA/float(20),\"Err RL=\",errL/float(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error for $\\eta=0.1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err perceptron= 0.12797202797202795 Err Adaline= 0.09195804195804197 Err RL= 0.0867132867132867\n"
     ]
    }
   ],
   "source": [
    "print(\"wbc:\")\n",
    "errAllModelsForEachDataSet(wdbc,0.1)\n",
    "print(\"ionosphere:\")\n",
    "errAllModelsForEachDataSet(iono,0.1)\n",
    "print(\"sonar\")\n",
    "errAllModelsForEachDataSet(sonar,0.1)\n",
    "print(\"spam\")\n",
    "errAllModelsForEachDataSet(spam,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err perceptron= 0.12613636363636363 Err Adaline= 0.10454545454545452 Err RL= 0.09886363636363636\n"
     ]
    }
   ],
   "source": [
    "errAllModelsForEachDataSet(iono,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err perceptron= 0.30384615384615393 Err Adaline= 0.30096153846153845 Err RL= 0.2548076923076924\n"
     ]
    }
   ],
   "source": [
    "errAllModelsForEachDataSet(sonar,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err perceptron= 0.2076455256298871 Err Adaline= 0.2700260642919201 Err RL= 0.16329278887923543\n"
     ]
    }
   ],
   "source": [
    "errAllModelsForEachDataSet(spam,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error for $\\eta=0.01$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err perceptron= 0.1006993006993007 Err Adaline= 0.07762237762237763 Err RL= 0.09265734265734266\n",
      "Err perceptron= 0.1090909090909091 Err Adaline= 0.10227272727272725 Err RL= 0.07386363636363635\n",
      "Err perceptron= 0.2663461538461539 Err Adaline= 0.2442307692307692 Err RL= 0.2663461538461538\n"
     ]
    }
   ],
   "source": [
    "print(\"wbc:\")\n",
    "errAllModelsForEachDataSet(wdbc,0.01)\n",
    "print(\"ionosphere:\")\n",
    "errAllModelsForEachDataSet(iono,0.01)\n",
    "print(\"sonar\")\n",
    "errAllModelsForEachDataSet(sonar,0.01)\n",
    "print(\"spam\")\n",
    "errAllModelsForEachDataSet(spam,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
